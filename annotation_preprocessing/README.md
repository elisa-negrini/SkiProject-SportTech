#  Annotation Preprocessing 

This folder contains the **annotation preprocessing pipeline** that transforms raw COCO-format exports from [Roboflow](https://roboflow.com/) into clean, interpolated, and normalized keypoint annotations ready for downstream metric computation and model training.

---

##  Folder Structure

```
annotation_preprocessing/
â”œâ”€â”€ main.py                        # Workflow orchestrator
â”œâ”€â”€ raw_annotations/               # Input COCO annotations from Roboflow
â””â”€â”€ utils/                         # Function classes used for annotation pipeline
```


---

## ğŸ”„ Pipeline Overview & Modules

The pipeline is executed interactively through `main.py`. For each jump, the following steps are performed in sequence:

| Step | Module | Description |
|------|--------|-------------|
| **1. Extract** | `annotation_manager.py` | Parses the full COCO export and extracts annotations for a specific jump using Roboflow user tags.  |
| **2. Filter Boxes** | `box_filter.py`  | Filters bounding boxes by removing entries corresponding to frames that were manually excluded (removed/occluded). |
| **3. Interpolate** | `interpolator.py`  | Linearly interpolates keypoints between manually annotated frames (~60) to fill all ~350 frames of each jump.  |
| **4. Visualize** | `visualizer.py`  | Generates annotated images with skeleton overlays and compiles them into an MP4 video for quality inspection. Draws color-coded skeletons and bounding boxes on video frames. |
| **5. Normalize** | `normalizer.py`  | Applies anatomical normalization (pelvis-rooted, hybrid body-scale) and fixed scaling to map all keypoints into a resolution- and position-independent [0, 1] coordinate space. Generates grid visualizations and outputs per-jump normalized data. |

After all jumps are processed, the `Normalizer` aggregates all normalized annotations into a single `keypoints_dataset.csv` file.

---

## â–¶ï¸ How to Run

**1.** Download `raw_annotations/` from [Google Drive](https://drive.google.com/drive/folders/10cKnZdP3x-tIoTHMw_nk2GYT9gc-uXRN?usp=drive_link) and place it inside `annotation_preprocessing/`.

**2.** Make sure the `dataset/frames/` folder is also available (otherwise downdload from [Google Drive](https://drive.google.com/drive/folders/10cKnZdP3x-tIoTHMw_nk2GYT9gc-uXRN?usp=drive_link)).

**3.** Run the pipeline from the project root:

```bash
python annotation_preprocessing/main.py
```

**4.** The script will interactively ask for:
- **Jump range** â€” e.g. `1-5` or `6`
- **Interpolation** â€” whether to interpolate between annotated frames
- **Visualization** â€” whether to generate overlay video
- **Normalization** â€” whether to normalize keypoints

---

## ğŸ“¤ Output

All output is written to the `dataset/` folder:

```
dataset/
â”œâ”€â”€ annotations/JP00XX/train/
â”‚   â”œâ”€â”€ annotations_jump{N}.json                  # Extracted per-jump COCO annotations
â”‚   â”œâ”€â”€ annotations_interpolated_jump{N}.coco.json # Interpolated annotations (all frames)
â”‚   â”œâ”€â”€ annotations_normalized_jump{N}.coco.json   # Normalized annotations
â”‚   â””â”€â”€ visualization_normalized_grid_jump{N}.png  # Normalization quality check grid
â”œâ”€â”€ annotations/JP00XX/visualizations/
â”‚   â”œâ”€â”€ frame_XXXXX.jpg                            # Skeleton overlay images
â”‚   â””â”€â”€ output_video_JP00XX.mp4                    # Overlay video
â””â”€â”€ keypoints_dataset.csv                          # Aggregated normalized keypoints (all jumps)
```

The generated `keypoints_dataset.csv` is the primary input for the `metrics/` pipeline.

---
