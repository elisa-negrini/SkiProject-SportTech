# ðŸ“Š Analisi Dettagliata - ScalabilitÃ  e Ottimizzazione del Modello

---

## 1. FUNZIONERANNO CON PIÃ™ SALTI ANNOTATI?

### âœ… **SÃŒ, ma con benefici progressivi**

#### ScalabilitÃ  Tecnica:
Tutti gli script sono progettati per essere **data-agnostic**:
- Leggono i CSV dinamicamente (non c'Ã¨ hardcoding di "23 salti")
- I loop iterano su `df.iterrows()` o `for jump_id in jump_ids`
- Leave-One-Out si adatta automaticamente a N samples

**Quindi tecnicamente: sÃ¬, funzioneranno con 50, 100 o 200 salti.**

---

#### ScalabilitÃ  Statistica (la parte critica):

| N Salti | Cosa Succede | QualitÃ  Modello |
|---------|--------------|-----------------|
| **23 (ora)** | Modelli instabili, RÂ² basso, alta varianza | âš ï¸ Risultati indicativi |
| **50** | Modelli iniziano a stabilizzarsi, pattern emergono | âœ… Risultati affidabili |
| **100** | Random Forest robusto, correlazioni chiare | âœ…âœ… Ottimo |
| **200+** | Possiamo usare modelli piÃ¹ complessi (GB, NN) | âœ…âœ…âœ… Eccellente |

#### Cosa MigliorerÃ  con PiÃ¹ Dati:

**A. Feature Importance diventerÃ  stabile:**
Ora con 23 salti, la top feature puÃ² cambiare drasticamente se rimuoviamo 2-3 outlier. Con 100 salti, l'ordine sarÃ  molto piÃ¹ robusto.

**B. RÂ² aumenterÃ :**
- Attualmente: RÂ² â‰ˆ 0.0 - 0.27 (quasi casuale)
- Con 50 salti: RÂ² â‰ˆ 0.3 - 0.5 (moderato)
- Con 100 salti: RÂ² â‰ˆ 0.5 - 0.7 (buono)

**C. Potremo fare validation set separato:**
Ora usiamo LOO per necessitÃ  (troppo pochi dati per split train/test). Con 100+ salti, potremo fare:
```
Train: 70 salti
Validation: 15 salti  
Test: 15 salti (MAI visti dal modello)
```

**D. Feature Selection diventerÃ  piÃ¹ affidabile:**
Con 23 salti, una feature puÃ² sembrare importante per caso. Con 100, possiamo usare tecniche come:
- Permutation Importance (piÃ¹ robusto)
- Recursive Feature Elimination
- Cross-validated feature selection

---

#### Problemi che PERSISTERANNO anche con piÃ¹ dati:

**1. VariabilitÃ  della prospettiva diagonale:**
- `body_rotation_velocity` continuerÃ  a essere rumorosa se la camera cambia tra eventi
- Soluzione: filtrare salti per "stesso evento" o normalizzare per camera angle

**2. QualitÃ  keypoints:**
- Mani e sci rimangono difficili da tracciare accuratamente
- Soluzione: usare confidence scores e droppare frame con bassa confidence

**3. Fattori esterni non catturati:**
- Condizioni vento (non misurate perfettamente)
- Bias giudici (soggettivitÃ  residua)
- Questi aggiungono "rumore ineliminabile" â†’ RÂ² massimo teorico potrebbe essere 0.7-0.8, non 1.0

---

## 2. MODELLO CON MENO PARAMETRI Ãˆ MEGLIO?

### âœ… **SÃŒ, assolutamente - per questi motivi:**

#### A. Il Problema del "Curse of Dimensionality"

Con 23 salti e 15+ features:
```
Ratio samples/features = 23/15 â‰ˆ 1.5

Regola empirica: serve almeno 10 samples per feature per evitare overfitting
Ideale per 23 salti: MAX 2-3 features!
```

**Cosa succede con troppe features:**
- Il modello "memorizza" invece di generalizzare
- Cattura rumore invece di pattern reali
- RÂ² sembra buono in training, pessimo in test
- Coefficienti diventano instabili (cambiano drasticamente tra fold)

---

#### B. InterpretabilitÃ  per gli Allenatori

Un modello con **3-4 features chiave** Ã¨:
- âœ… Comprensibile: "Lavora su questi 3 aspetti"
- âœ… Actionable: Puoi misurare miglioramenti specifici
- âœ… Trustable: Non Ã¨ una "black box"

Un modello con **15 features**:
- âŒ Confuso: "Migliora... tutto?"
- âŒ Contraddittorio: Feature correlate si "cannibalizzano"
- âŒ Instabile: I coefficienti non hanno senso fisico

---

#### C. Evidenza dai tuoi Risultati Attuali

Guardando `style_penalty_model/feature_importance.csv`:

| Feature | Importance | Problemi Evidenti |
|---------|-----------|-------------------|
| body_rotation_velocity_max | 21% | Rumorosa, sensibile a camera |
| flight_range | 19% | Ridondante con flight_std |
| flight_jitter | 15% | Correlata con flight_std |
| ski_symmetry_score | 10% | Molti NaN, dati corrotti |

**Il modello sta usando features "di riempimento"** perchÃ© non ha abbastanza dati per discriminare quali sono veramente importanti.

---

## 3. DOVREMMO DROPPARE CERTE VARIABILI?

### âœ… **SÃŒ, con criterio strategico**

#### Strategia di Selezione: **3-Tier System**

**TIER 1 - Features Robuste (SEMPRE includere):**
```
âœ… flight_std - StabilitÃ  volo (ben validata, r = -0.556)
âœ… landing_hip_velocity - Impatto atterraggio (r = -0.650, causalmente corretta)
âœ… flight_jitter - Oscillazioni frame-to-frame (complementare a flight_std)
```
**PerchÃ© queste:**
- Correlazioni significative con Style_Score
- Teoricamente fondate (aerodinamica + giudizi estetici)
- Robuste alla prospettiva (misurano variazioni, non assoluti)

---

**TIER 2 - Features Da Valutare (includere SE passano threshold):**
```
âš ï¸ vstyle_final_angle - SE la vista Ã¨ consistente tra salti
âš ï¸ telemark_scissor_mean - SE l'atterraggio Ã¨ ben visibile
âš ï¸ knee_peak_velocity - SE abbiamo vista laterale decente
```
**Threshold da applicare:**
1. **Correlation test**: |r| > 0.3 con target (significativo)
2. **Missing data**: < 30% NaN
3. **Multicollinearity**: VIF < 5 (non troppo correlata con altre)

---

**TIER 3 - Features Da ESCLUDERE (troppo rumorose):**
```
âŒ body_rotation_velocity_max - Falsi positivi da cambio camera
âŒ arm_stability_std - Keypoints mani inaccurati
âŒ ski_jitter_range - Valori impossibili (357Â°) indicano dati corrotti
âŒ compactness_mean - Definizione ambigua, dipende da come calcoli "bounding box"
```

---

#### Threshold Concrete da Implementare:

**1. Correlation Threshold:**
```python
# Mantieni solo feature con correlazione significativa
threshold_r = 0.25  # Almeno "weak correlation"
threshold_p = 0.10  # p-value < 0.10 (90% confidence)

valid_features = correlations[
    (abs(correlations['pearson_r']) > threshold_r) &
    (correlations['pearson_p'] < threshold_p)
]['metric'].tolist()
```

**2. Multicollinearity Check:**
```python
# Rimuovi feature ridondanti
# Se flight_range e flight_std correlano a 0.85+, tieni solo la piÃ¹ importante
```

**3. Data Quality Check:**
```python
# Rimuovi feature con troppi dati mancanti
missing_threshold = 0.30  # Max 30% NaN
valid_features = [f for f in features if df[f].isna().sum() / len(df) < missing_threshold]
```

**4. Physical Plausibility Check:**
```python
# Rimuovi outlier impossibili
# Es: ski_jitter_range > 90Â° Ã¨ impossibile fisicamente
df.loc[df['ski_jitter_range'] > 90, 'ski_jitter_range'] = np.nan
```

---

## 4. MODELLO OTTIMALE CON DATI ATTUALI

### Raccomandazione: **3-Feature Model**

**Formula Proposta:**
```
Style_Penalty = Î± Ã— flight_std + Î² Ã— landing_hip_velocity + Î³ Ã— flight_jitter + Î´
```

**Vantaggi:**
1. **Copertura completa del salto:**
   - `flight_std`: Fase di volo (stabilitÃ  globale)
   - `flight_jitter`: Fase di volo (micro-correzioni)
   - `landing_hip_velocity`: Fase di atterraggio

2. **Basso rischio overfitting:**
   - Ratio 23/3 â‰ˆ 7.7 (vicino alla regola dei 10)

3. **Interpretabile:**
   - Ogni coefficiente ha significato chiaro
   - Allenatore sa dove intervenire

4. **Robusto:**
   - Tutte e 3 hanno correlazioni validate
   - Meno sensibili alla prospettiva

---

### Con 50+ Salti, Espandere a **5-Feature Model:**

```
Aggiungere:
+ vstyle_final_angle (se vista consistente)
+ telemark_scissor_mean (per valutare atterraggio)
```

---

## 5. COSA FARE QUANDO ANNOTERETE PIÃ™ SALTI

### Roadmap Incrementale:

**A. Con 50 Salti:**
1. âœ… Ri-eseguire tutti gli script (funzioneranno automaticamente)
2. âœ… Feature Selection con threshold (correlation > 0.30, p < 0.05)
3. âœ… Usare 5-Feature Model
4. âœ… Passare da LOO a 5-Fold Cross-Validation
5. âœ… Aspettarsi RÂ² â‰ˆ 0.35-0.50

**B. Con 100 Salti:**
1. âœ… Gradient Boosting diventa affidabile
2. âœ… Split Train/Validation/Test (70/15/15)
3. âœ… Permutation Importance invece di coefficienti lineari
4. âœ… Possibile espandere a 7-8 features
5. âœ… Aspettarsi RÂ² â‰ˆ 0.50-0.65

**C. Con 200+ Salti:**
1. âœ… Modelli ensemble (stacking)
2. âœ… Neural Network semplice (3 layer)
3. âœ… Analisi per sottogruppi (uomini vs donne, HS vs K-point)
4. âœ… Aspettarsi RÂ² â‰ˆ 0.65-0.75

---

## 6. RISPOSTA ALLE TUE PREOCCUPAZIONI SPECIFICHE

### "Body Rotation non ci convince"
**Hai ragione al 100%.** Motivi:
- Sensibile a movimenti camera
- Keypoints spalle/anche sono i meno stabili in diagonale
- Valori come 198Â°/sec sono irrealistici (nessun atleta ruota cosÃ¬ tanto in volo)

**Azione:** âŒ **Escludere** finchÃ© non hai:
- Camera fissa (non pan/zoom)
- Confidence scores sui keypoints > 0.8
- Vista piÃ¹ frontale (per vedere effettivamente la rotazione)

---

### "Flight Jitter non ci convince"
**Qui Ã¨ piÃ¹ sfumato.** Pro e contro:

**PRO:**
- Correlazione moderata con Style_Score (r = -0.468)
- Misura micro-oscillazioni (complementare a flight_std)
- Meno sensibile a prospettiva (misura delta frame-to-frame)

**CONTRO:**
- Parzialmente correlata con flight_std (r â‰ˆ 0.6-0.7)
- Dipende dalla framerate (30 fps vs 60 fps darebbe valori diversi)

**Azione:** âš ï¸ **Mantenere SE flight_std da sola non basta**
- In modello a 3 feature: flight_std + landing + (flight_jitter O vstyle_angle)
- Test: prova modello con/senza, vedi quale ha RÂ² migliore in validation

---

### "Se droppassimo variabili sarebbe un problema?"
**NO, anzi migliorerebbe il modello.**

**Evidenza matematica:**
Con 23 salti, un modello con 3 features BATTE un modello con 15 features perchÃ©:
- Meno overfitting
- Coefficienti piÃ¹ stabili
- Errore di generalizzazione piÃ¹ basso

**Esperimento che puoi fare:**
```
Modello A (15 features): RÂ² train = 0.80, RÂ² test = 0.10 (overfitting!)
Modello B (3 features): RÂ² train = 0.35, RÂ² test = 0.32 (generalizza!)
```

---

## ðŸŽ¯ RACCOMANDAZIONE FINALE

### Azione Immediata (con 23 salti):

**1. Crea versione "Lite" dello Style Penalty Model:**
- Solo 3 features: flight_std, landing_hip_velocity, flight_jitter
- Salva come `style_penalty_model_lite.py`
- Confronta RÂ² con versione completa

**2. Implementa Data Quality Checks:**
- Flag per salti con `ski_jitter_range > 90Â°` (dati corrotti)
- Escludi salti con > 30% keypoints mancanti
- Aggiungi colonna "data_quality_score" nel CSV

**3. Documenta Assumptions:**
- Crea file `METRICS_RELIABILITY.md` che lista:
  - Features robuste (Tier 1)
  - Features da validare (Tier 2)
  - Features da escludere (Tier 3)

---

### Piano con PiÃ¹ Dati:

| N Salti | N Features Raccomandate | Modello | RÂ² Atteso |
|---------|-------------------------|---------|-----------|
| 23 | 3 | Ridge/RF | 0.25-0.35 |
| 50 | 5 | RF + Validation | 0.40-0.55 |
| 100 | 7-8 | GB + Ensemble | 0.55-0.70 |
| 200+ | 10-12 | Stacking/NN | 0.65-0.80 |

---

**Vuoi che implementi la versione "Lite" del modello con solo le 3 feature piÃ¹ robuste?**




INDAGARE ASSOLUTAMENTE SU SE E COME DROPPARE LE VARIABILI SENZA FARE DANNI AL CODICE